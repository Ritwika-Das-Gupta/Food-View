{"metadata":{"kernelspec":{"language":"python","display_name":"Python 3","name":"python3"},"language_info":{"name":"python","version":"3.10.14","mimetype":"text/x-python","codemirror_mode":{"name":"ipython","version":3},"pygments_lexer":"ipython3","nbconvert_exporter":"python","file_extension":".py"},"kaggle":{"accelerator":"tpu1vmV38","dataSources":[{"sourceId":9137943,"sourceType":"datasetVersion","datasetId":5518537},{"sourceId":9138837,"sourceType":"datasetVersion","datasetId":5519216}],"dockerImageVersionId":30747,"isInternetEnabled":true,"language":"python","sourceType":"notebook","isGpuEnabled":false}},"nbformat_minor":4,"nbformat":4,"cells":[{"cell_type":"code","source":"import pandas as pd\npd.set_option(\"display.max_columns\",False)","metadata":{"execution":{"iopub.status.busy":"2024-08-16T11:27:41.193316Z","iopub.execute_input":"2024-08-16T11:27:41.193696Z","iopub.status.idle":"2024-08-16T11:27:43.012896Z","shell.execute_reply.started":"2024-08-16T11:27:41.193667Z","shell.execute_reply":"2024-08-16T11:27:43.011873Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"pip install openpyxl","metadata":{"execution":{"iopub.status.busy":"2024-08-16T11:27:43.014483Z","iopub.execute_input":"2024-08-16T11:27:43.014809Z","iopub.status.idle":"2024-08-16T11:27:47.774036Z","shell.execute_reply.started":"2024-08-16T11:27:43.014783Z","shell.execute_reply":"2024-08-16T11:27:47.772831Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"df=pd.read_excel(\"/kaggle/input/finala/zomato_final.xlsx\",sheet_name=\"Sheet1\")","metadata":{"execution":{"iopub.status.busy":"2024-08-16T11:27:47.775375Z","iopub.execute_input":"2024-08-16T11:27:47.775646Z","iopub.status.idle":"2024-08-16T11:27:55.874384Z","shell.execute_reply.started":"2024-08-16T11:27:47.775619Z","shell.execute_reply":"2024-08-16T11:27:55.873502Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"import ast\nimport ast\nfrom transformers import AutoModelForSequenceClassification, AutoTokenizer, AutoConfig\nimport numpy as np\nfrom scipy.special import softmax\nfrom collections import Counter\n","metadata":{"execution":{"iopub.status.busy":"2024-08-16T11:27:55.897309Z","iopub.execute_input":"2024-08-16T11:27:55.905153Z","iopub.status.idle":"2024-08-16T11:28:17.890912Z","shell.execute_reply.started":"2024-08-16T11:27:55.905120Z","shell.execute_reply":"2024-08-16T11:28:17.889936Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"def preprocess(text):\n    new_text = []\n    for t in text.split(\" \"):\n        t = '@user' if t.startswith('@') and len(t) > 1 else t\n        t = 'http' if t.startswith('http') else t\n        new_text.append(t)\n    return \" \".join(new_text)","metadata":{"execution":{"iopub.status.busy":"2024-08-16T11:28:17.892042Z","iopub.execute_input":"2024-08-16T11:28:17.892486Z","iopub.status.idle":"2024-08-16T11:28:17.897746Z","shell.execute_reply.started":"2024-08-16T11:28:17.892454Z","shell.execute_reply":"2024-08-16T11:28:17.896979Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"# Load model and tokenizer\nMODEL = \"cardiffnlp/twitter-roberta-base-sentiment-latest\"\ntokenizer = AutoTokenizer.from_pretrained(MODEL)\nconfig = AutoConfig.from_pretrained(MODEL)\nmodel = AutoModelForSequenceClassification.from_pretrained(MODEL)\n\ndef sentiment(x):\n    reviews_list = ast.literal_eval(x)[:20]\n    sentiments=[]\n    reviews = [review[1] for review in reviews_list]\n#     print(type(reviews))\n# Preprocess text (username and link placeholders)\n\n\n\n\n    # Analyze sentiment for each review\n    for i, review in enumerate(reviews):\n        text = preprocess(review)\n#         print(review)\n        encoded_input = tokenizer(text, return_tensors='pt',max_length=512)\n        output = model(**encoded_input)\n        scores = output[0][0].detach().numpy()\n        scores = softmax(scores)\n\n        ranking = np.argsort(scores)[::-1]\n        sentiment = config.id2label[ranking[0]]\n        score = scores[ranking[0]]\n        sentiments.append(sentiment)\n    return(sentiments)\n\n    \n    \n","metadata":{"execution":{"iopub.status.busy":"2024-08-16T11:28:17.898651Z","iopub.execute_input":"2024-08-16T11:28:17.898897Z","iopub.status.idle":"2024-08-16T11:28:34.486145Z","shell.execute_reply.started":"2024-08-16T11:28:17.898873Z","shell.execute_reply":"2024-08-16T11:28:34.484896Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"def freq(l):\n    return Counter(l)","metadata":{"execution":{"iopub.status.busy":"2024-08-16T11:28:34.488100Z","iopub.execute_input":"2024-08-16T11:28:34.488559Z","iopub.status.idle":"2024-08-16T11:28:34.493356Z","shell.execute_reply.started":"2024-08-16T11:28:34.488526Z","shell.execute_reply":"2024-08-16T11:28:34.492513Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"df1=df[5000:15000]","metadata":{"execution":{"iopub.status.busy":"2024-08-16T11:28:34.496413Z","iopub.execute_input":"2024-08-16T11:28:34.496727Z","iopub.status.idle":"2024-08-16T11:28:34.509501Z","shell.execute_reply.started":"2024-08-16T11:28:34.496702Z","shell.execute_reply":"2024-08-16T11:28:34.508701Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"def process_group(group):\n    # Apply sentiment function to the first 20 rows of the group\n    sentiments = group.head(20)['reviews_list'].apply(sentiment)\n    \n    # Flatten the list of lists to a single list\n    all_sentiments = [item for sublist in sentiments for item in sublist]\n    \n    # Get the frequency of each sentiment\n    sentiment_counts = freq(all_sentiments)\n    \n    # Extract the counts of 'positive', 'negative', and 'neutral'\n    positive = sentiment_counts.get('positive', 0)\n    negative = sentiment_counts.get('negative', 0)\n    neutral = sentiment_counts.get('neutral', 0)\n    \n    return pd.Series([positive, negative, neutral], index=['positive', 'negative', 'neutral'])\n\n# Apply the process_group function to each group\nresult = df1.groupby('name').apply(process_group)","metadata":{"execution":{"iopub.status.busy":"2024-08-16T11:28:34.510429Z","iopub.execute_input":"2024-08-16T11:28:34.510673Z","iopub.status.idle":"2024-08-16T11:29:05.523913Z","shell.execute_reply.started":"2024-08-16T11:28:34.510648Z","shell.execute_reply":"2024-08-16T11:29:05.522948Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"result.to_csv(\"sentiments.csv\")","metadata":{"execution":{"iopub.status.busy":"2024-08-16T11:29:05.525267Z","iopub.execute_input":"2024-08-16T11:29:05.525611Z","iopub.status.idle":"2024-08-16T11:29:05.534477Z","shell.execute_reply.started":"2024-08-16T11:29:05.525579Z","shell.execute_reply":"2024-08-16T11:29:05.533586Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"","metadata":{},"execution_count":null,"outputs":[]}]}